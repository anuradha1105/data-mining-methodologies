# ğŸ’³ Credit Card Fraud Detection using the KDD Process  
_A complete end-to-end Knowledge Discovery in Databases (KDD) project_

---

## ğŸ§  Overview  

This project applies the **KDD (Knowledge Discovery in Databases)** methodology to detect fraudulent credit card transactions from a real-world dataset.  
The analysis demonstrates how systematic data mining â€” guided by the KDD process â€” can yield interpretable, ethical, and operationally reliable insights in the financial fraud domain.

The pipeline includes five core KDD phases:  
1. **Selection** â€” identify relevant, ethical data sources  
2. **Preprocessing** â€” clean and prepare data  
3. **Transformation** â€” engineer features and handle imbalance  
4. **Data Mining** â€” train and validate predictive models  
5. **Interpretation** â€” extract actionable and ethical knowledge  

---

## ğŸ“‚ Dataset Summary  

| Attribute | Description |
|------------|-------------|
| **Name** | Credit Card Fraud Detection |
| **Source** | UniversitÃ© Libre de Bruxelles (ULB) / Kaggle ([mlg-ulb/creditcardfraud](https://www.kaggle.com/mlg-ulb/creditcardfraud)) |
| **Records** | ~284,807 transactions |
| **Features** | 30 (28 PCA components + Time + Amount + Class) |
| **Label (Target)** | `Class`: 0 = Legitimate, 1 = Fraud |
| **Fraud Ratio** | â‰ˆ 0.17% (highly imbalanced) |
| **Ethics** | Fully anonymized, GDPR-compliant, no PII |

---

## ğŸ Phase 1 â€” Selection  

### ğŸ¯ Objective  
To identify a reliable and representative dataset suitable for fraud detection while ensuring ethical and compliance standards.

### ğŸ” Highlights  
- **Dataset chosen:** European Credit Card Transactions (ULB/Kaggle)  
- **Scope:** Two days of anonymized financial transactions  
- **Challenge:** Only 0.17% fraudulent cases â€” realistic class imbalance  
- **Goal:** Predict rare fraud accurately with minimal false positives  

### âš–ï¸ Ethical Safeguards  
- No personal identifiers (names, IDs, merchants)  
- Compliant with GDPR and academic data-use policy  
- Purpose limited to educational and research experimentation  

### âš ï¸ Risks and Mitigations  

| Risk | Impact | Mitigation |
|------|---------|------------|
| Extreme class imbalance | High | Use SMOTE, class weighting, or anomaly detection |
| Limited temporal diversity | Medium | Treat results as illustrative, not deployable |
| PCA anonymization reduces interpretability | Medium | Use SHAP explanations for post-hoc transparency |

### âœ… Outcome  
A valid, ethical dataset selected for downstream KDD analysis, balancing research realism and governance compliance.

---

## ğŸ§¹ Phase 2 â€” Preprocessing  

### ğŸ¯ Objective  
To ensure the dataset is clean, consistent, and structurally ready for modeling.

### ğŸ§­ Steps  
1. Verified data completeness â€” no missing or duplicate entries.  
2. Confirmed all features are numeric (no categorical encoding required).  
3. Standardized contextual features: `Amount`, `Time`.  
4. Stratified trainâ€“test split (80/20) to preserve fraud ratio.  

### ğŸ§¾ Code Snapshot  
```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df[['Amount', 'Time']] = scaler.fit_transform(df[['Amount', 'Time']])

X = df.drop('Class', axis=1)
y = df['Class']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)
```

### Risks and Mitigation ## ğŸ Phase 1 â€” Selection

| Risk                | Impact | Mitigation                             |
| ------------------- | ------ | -------------------------------------- |
| Data leakage        | High   | Fit scalers only on training data      |
| Outliers in Amount  | Medium | Apply log transform                    |
| Unbalanced test set | Medium | Stratified split maintains fraud ratio |


### Outcomeâ€¨Clean, scaled dataset ready for transformation and modeling.

## ğŸ”„ Phase 3 â€” Transformation
### Objectiveâ€¨Enhance model learnability by engineering features, balancing classes, and ensuring scale consistency.
- Applied SMOTE for minority class resampling.
- Created derived features: `Amount_log`, `Amount_square`.
- Verified integrity via nearest-neighbor distance plots.

**ğŸ§¾ Code Example**
from imblearn.over_sampling import SMOTE
```
smote = SMOTE(k_neighbors=5, random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

```
**ğŸ“Š Class Balancing**
Before resampling: Counter({0: 226602, 1: 378})
After resampling : Counter({0: 226602, 1: 226602})

**âœ… Outcome**

<img width="582" height="472" alt="image" src="https://github.com/user-attachments/assets/765f03a2-3199-4d38-bdd9-cdd700862dd1" />

Balanced, feature-rich dataset with robust scaling and augmentation.


**ğŸ¤– Phase 4 â€” Data Mining
ğŸ¯ Objective**

Train and compare supervised models to predict fraud effectively.

ğŸ§© Models Used
| Model               | Type              | Rationale                   |
| ------------------- | ----------------- | --------------------------- |
| Logistic Regression | Linear            | Baseline interpretability   |
| Random Forest       | Ensemble          | Robust, non-linear learning |
| XGBoost             | Gradient Boosting | High accuracy, low bias     |

**ğŸ§¾ Code Example**

```
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1),
    "XGBoost": XGBClassifier(n_estimators=300, max_depth=6, learning_rate=0.1, subsample=0.8,
                             colsample_bytree=0.8, random_state=42, n_jobs=-1)
}

for name, model in models.items():
    model.fit(X_train_res, y_train_res)
    print(f"âœ… {name} trained successfully.")

```


ğŸ“ˆ Evaluation Metrics


<img width="673" height="151" alt="image" src="https://github.com/user-attachments/assets/13b1fffe-a36b-4e0d-a1a9-b91fe5a8b4d7" />


**ğŸ§  Key Findings**
Random Forest achieved highest recall and AUC
Top features: V14, V12, V10, Amount_log
Ensemble models outperform linear baselines

**âš ï¸ Risks and Mitigation**
| Risk                       | Impact | Mitigation                   |
| -------------------------- | ------ | ---------------------------- |
| Overfitting                | High   | Cross-validation and pruning |
| Imbalance in real test set | Medium | Use class weights            |
| Model interpretability     | Medium | Add SHAP explainability      |

**âœ… Outcome**
Random Forest selected as champion model with near-perfect fraud detection accuracy and explainability.
**
**ğŸ” Phase 5 â€” Interpretation
ğŸ¯ Objective****
Translate model outcomes into business, behavioral, and ethical insights.

ğŸ”‘ Model Insights
| Feature             | Insight                                    |
| ------------------- | ------------------------------------------ |
| `V14`, `V12`, `V10` | Encapsulate behavioral anomalies           |
| `Amount_log`        | High-value spikes correlate with fraud     |
| PCA outliers        | Capture deviation from normal transactions |


**ğŸ“Š Visual Interpretations**

- SHAP Summary Plot â€” feature importance
- Precisionâ€“Recall Curve â€” fraud threshold tuning
- 
  <img width="597" height="444" alt="image" src="https://github.com/user-attachments/assets/3e45ff00-d993-4ed9-90db-884e37e6aa06" />

- Confusion Matrix â€” balanced accuracy
- 
- <img width="587" height="479" alt="image" src="https://github.com/user-attachments/assets/2dc17d9c-13d1-4d07-b951-29e775ab12ef" />

- PDPs â€” show impact of top features on predictions
- 
- <img width="721" height="473" alt="image" src="https://github.com/user-attachments/assets/470a5188-afd6-4dd6-9883-e2ad8066eac6" />


**âš–ï¸ Ethical and Governance Compliance**
| Principle      | Implementation                                    |
| -------------- | ------------------------------------------------- |
| Transparency   | SHAP explanations attached to each prediction     |
| Accountability | Quarterly retraining and drift monitoring         |
| Fairness       | Demographic parity audits planned                 |
| Regulation     | EU AI Act and IEEE P7003-aligned model governance |

**âœ… Outcome**
An explainable, auditable, and ethical fraud detection framework ready for deployment.

**ğŸ§© Key Takeaways**
| Lesson                        | Insight                                                |
| ----------------------------- | ------------------------------------------------------ |
| KDD is holistic               | From Selection to Interpretation â€” data to knowledge   |
| Handling imbalance is key     | SMOTE, weighting, and threshold tuning crucial         |
| Interpretability builds trust | SHAP and feature importance make decisions transparent |
| Accuracy â‰  Success            | Ethical, reproducible systems matter equally           |
| Continuous monitoring needed  | Model drift tracking maintains fairness and precision  |


**ğŸ Executive Summary**
The KDD Fraud Detection Project demonstrates a complete, end-to-end implementation of the Knowledge Discovery in Databases framework.

**ğŸ¯ Key Achievements****
- Achieved ROC-AUC â‰ˆ 0.998 and Recall â‰ˆ 0.96 using Random Forest
- Balanced class distribution using SMOTE for fairness
- Built fully reproducible and ethical AI pipeline
- Applied SHAP for model explainability
- Designed governance-compliant monitoring protocol
